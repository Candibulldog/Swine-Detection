# train.py

import os
import random

import pandas as pd
import torch

# å¾ src è³‡æ–™å¤¾ä¸­å¼•å…¥æˆ‘å€‘å¯«å¥½çš„æ¨¡çµ„
from src.dataset import PigDataset
from src.engine import evaluate, train_one_epoch
from src.model import create_model
from src.transforms import get_transform
from src.utils import collate_fn
from torch.utils.data import DataLoader

# ==================================
# 1. è¶…åƒæ•¸è¨­å®š (Hyperparameters)
# ==================================
DEVICE = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
NUM_CLASSES = 2  # 1 (pig) + 1 (background)
NUM_EPOCHS = 10
BATCH_SIZE = 4
LEARNING_RATE = 0.005
DATA_ROOT = "/content/data"  # åœ¨ Colab ä¸­çš„è³‡æ–™è·¯å¾‘


def main():
    # ==================================
    # 2. æº–å‚™è³‡æ–™ (Dataset & DataLoader)
    # ==================================
    # 1. å…ˆè®€å–ä¸€æ¬¡å®Œæ•´çš„æ¨™è¨»æª”
    annotations_path = os.path.join(DATA_ROOT, "train", "gt.txt")
    column_names = ["frame", "bb_left", "bb_top", "bb_width", "bb_height"]
    full_annotations = pd.read_csv(annotations_path, header=None, names=column_names)

    # 2. ç²å–æ‰€æœ‰ç¨ä¸€ç„¡äºŒçš„åœ–ç‰‡ frame IDï¼Œä¸¦æ‰“äº‚é †åº
    all_frames = full_annotations["frame"].unique()
    random.shuffle(all_frames)  # <-- éœ€è¦ import random

    # 3. åˆ‡åˆ† frame ID åˆ—è¡¨
    split_point = int(0.8 * len(all_frames))
    train_frames = all_frames[:split_point]
    val_frames = all_frames[split_point:]

    # 4. æ ¹æ“šåˆ‡åˆ†å¥½çš„ frame ID ä¾†éæ¿¾ DataFrame
    train_df = full_annotations[full_annotations["frame"].isin(train_frames)]
    val_df = full_annotations[full_annotations["frame"].isin(val_frames)]

    # 5. ç”¨åˆ‡åˆ†å¥½çš„ DataFrame ä¾†åˆå§‹åŒ–å…©å€‹ç¨ç«‹çš„ Dataset
    train_dataset = PigDataset(root_dir=DATA_ROOT, transforms=get_transform(train=True), annotations_df=train_df)
    val_dataset = PigDataset(root_dir=DATA_ROOT, transforms=get_transform(train=False), annotations_df=val_df)

    # å»ºç«‹ DataLoader (é€™éƒ¨åˆ†ä¸è®Š)
    train_loader = DataLoader(
        train_dataset,
        batch_size=BATCH_SIZE,
        shuffle=True,
        collate_fn=collate_fn,
    )
    val_loader = DataLoader(
        val_dataset,
        batch_size=BATCH_SIZE,
        shuffle=False,
        collate_fn=collate_fn,
    )

    print(f"è¨“ç·´é›†å¤§å°: {len(train_dataset)}")
    print(f"é©—è­‰é›†å¤§å°: {len(val_dataset)}")

    # ==================================
    # 3. å»ºç«‹æ¨¡å‹å’Œå„ªåŒ–å™¨
    # ==================================
    model = create_model(NUM_CLASSES)
    model.to(DEVICE)

    # è¨­å®šå„ªåŒ–å™¨ (SGD æ˜¯ä¸€å€‹ç©©å¥çš„é¸æ“‡)
    params = [p for p in model.parameters() if p.requires_grad]
    optimizer = torch.optim.SGD(params, lr=LEARNING_RATE, momentum=0.9, weight_decay=0.0005)

    print("\n--- æª¢æŸ¥è¨­å‚™ ---")
    print(f"DEVICE is set to: {DEVICE}")

    # ==================================
    # 4. è¨“ç·´è¿´åœˆ (Training Loop)
    # ==================================
    best_map = 0.0  # ç”¨ä¾†è¨˜éŒ„ç›®å‰æœ€å¥½çš„ mAP åˆ†æ•¸

    print("\n--- é–‹å§‹è¨“ç·´ ---")
    for epoch in range(NUM_EPOCHS):
        train_one_epoch(model, optimizer, train_loader, DEVICE, epoch)

        # å‘¼å« evaluate ä¸¦ç²å–è©•ä¼°çµæœ
        coco_evaluator = evaluate(model, val_loader, DEVICE)

        # å¾è©•ä¼°çµæœä¸­æå– mAP_50:95 çš„åˆ†æ•¸ (å®ƒåœ¨ stats[0])
        current_map = coco_evaluator.coco_eval["bbox"].stats[0]

        # æª¢æŸ¥æ˜¯å¦æ˜¯ç›®å‰æœ€å¥½çš„æ¨¡å‹
        if current_map > best_map:
            best_map = current_map
            # å¦‚æœæ˜¯ï¼Œå°±å„²å­˜å®ƒï¼
            torch.save(model.state_dict(), "best_model.pth")
            print(f"ğŸ‰ New best model saved with mAP: {best_map:.4f} at epoch {epoch + 1}")

    print("\n--- è¨“ç·´å®Œæˆ ---")
    print(f"æ•´å€‹è¨“ç·´éç¨‹ä¸­æœ€å¥½çš„ mAP åˆ†æ•¸æ˜¯: {best_map:.4f}")

    # å„²å­˜æ¨¡å‹æ¬Šé‡
    torch.save(model.state_dict(), "fasterrcnn_pig_detector.pth")
    print("æ¨¡å‹å·²å„²å­˜è‡³ fasterrcnn_pig_detector.pth")


if __name__ == "__main__":
    main()
