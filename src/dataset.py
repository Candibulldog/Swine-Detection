# src/dataset.py - Cluster-Aware Version

from pathlib import Path
from typing import Dict, List, Optional

import pandas as pd
import torch
from PIL import Image
from torch.utils.data import Dataset

from src.transforms import get_transform


class PigDataset(Dataset):
    """
    Final cluster-aware dataset that correctly uses the transform factory.
    """

    def __init__(
        self,
        data_root: Path,
        frame_ids: Optional[List[int]],
        is_train: bool,
        annotations_df: Optional[pd.DataFrame] = None,
        cluster_dict: Optional[Dict[int, int]] = None,
        use_cluster_aware_aug: bool = False,
    ):
        self.data_root = Path(data_root)
        self.is_train = is_train
        self.cluster_dict = cluster_dict if cluster_dict else {}

        # æ ¹æ“šæ˜¯å¦æä¾›æ¨™è¨»ä¾†æ±ºå®šæ˜¯ 'train'/'val' æ¨¡å¼é‚„æ˜¯ 'test' æ¨¡å¼
        # é©—è­‰é›†çš„åœ–ç‰‡ä¹Ÿåœ¨ 'train/img' ä¸‹ï¼Œæ‰€ä»¥é€™å€‹é‚è¼¯æ˜¯æ­£ç¢ºçš„
        data_dir_name = "test" if annotations_df is None else "train"
        self.image_dir = self.data_root / data_dir_name / "img"

        # --- æ ¸å¿ƒä¿®æ­£: æ¨™è¨»åŠ è¼‰é‚è¼¯ ---
        # åªè¦æä¾›äº† annotations_df (ç„¡è«–æ˜¯è¨“ç·´é›†é‚„æ˜¯é©—è­‰é›†)ï¼Œå°±æ‡‰è©²åŠ è¼‰æ¨™è¨»
        if annotations_df is not None:
            if frame_ids is None:
                raise ValueError("frame_ids must be provided when annotations_df is given.")
            self.frame_ids = frame_ids
            # éæ¿¾å‡ºç•¶å‰ split (train/val) éœ€è¦çš„æ¨™è¨»
            self.annotations = annotations_df[annotations_df["frame"].isin(self.frame_ids)].copy()
            # è¨ˆç®— x2, y2 åæ¨™
            self.annotations["x1"] = self.annotations["bb_left"]
            self.annotations["y1"] = self.annotations["bb_top"]
            self.annotations["x2"] = self.annotations["bb_left"] + self.annotations["bb_width"]
            self.annotations["y2"] = self.annotations["bb_top"] + self.annotations["bb_height"]
            self.frame_annotations = self.annotations.groupby("frame")
        else:
            # é€™æ˜¯çµ¦ predict.py ä½¿ç”¨çš„çœŸæ­£ Test æ¨¡å¼ï¼Œæ²’æœ‰ä»»ä½•æ¨™è¨»
            if frame_ids is None:
                self.frame_ids = sorted([int(p.stem) for p in self.image_dir.glob("*.jpg") if p.stem.isdigit()])
            else:
                self.frame_ids = frame_ids
            # å‰µå»ºä¸€å€‹ç©ºçš„ annotations DataFrame
            self.annotations = pd.DataFrame(columns=["frame", "x1", "y1", "x2", "y2"])
            self.frame_annotations = self.annotations.groupby("frame")

        # --- Transform åˆå§‹åŒ–é‚è¼¯ (ä¸è®Š) ---
        # é€™å€‹é‚è¼¯ç”± self.is_train æ­£ç¢ºæ§åˆ¶ï¼Œæ±ºå®šäº†æ˜¯å¦æ‡‰ç”¨æ•¸æ“šå¢å¼·
        if self.is_train:
            self.transforms = {}
            if use_cluster_aware_aug and self.cluster_dict:
                print("INFO: Initializing Dataset with CLUSTER-AWARE transforms.")
                self.transforms[0] = get_transform(train=True, cluster_id=0, use_cluster_aware=True)
                self.transforms[1] = get_transform(train=True, cluster_id=1, use_cluster_aware=True)
                self.transforms[2] = get_transform(train=True, cluster_id=2, use_cluster_aware=True)
            else:
                print("INFO: Initializing Dataset with UNIFIED transform.")
                self.transforms["unified"] = get_transform(train=True, use_cluster_aware=False)
        else:
            # é©—è­‰/æ¸¬è©¦é›†åªæœ‰ä¸€ç¨® pipeline (Resize, Pad, Normalize, ToTensor)
            print("INFO: Initializing Dataset with VALIDATION/TEST transform.")
            self.transforms = {"val": get_transform(train=False)}

    def __len__(self):
        return len(self.frame_ids)

    def _get_image_path(self, frame_id: int) -> Path:
        filename = f"{frame_id:08d}.jpg"
        return self.image_dir / filename

    def __getitem__(self, idx: int):
        frame_id = self.frame_ids[idx]
        img_path = self._get_image_path(frame_id)
        image = Image.open(img_path).convert("RGB")

        target = {"image_id": torch.tensor([frame_id])}

        # --- æ ¸å¿ƒä¿®æ­£: Target å­—å…¸å¡«å…… ---
        # ç§»é™¤ is_train åˆ¤æ–·ï¼Œç¢ºä¿é©—è­‰é›†ä¹Ÿèƒ½æ‹¿åˆ°å« 'boxes' çš„ target å­—å…¸
        if frame_id in self.frame_annotations.groups:
            frame_data = self.frame_annotations.get_group(frame_id)
            boxes = frame_data[["x1", "y1", "x2", "y2"]].values
            labels = torch.ones(len(boxes), dtype=torch.int64)
            areas = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])

            # éæ¿¾æ‰ç„¡æ•ˆçš„ boxes
            valid_indices = areas > 0
            boxes = boxes[valid_indices]
            labels = labels[valid_indices]
            areas = areas[valid_indices]

            target["boxes"] = torch.as_tensor(boxes, dtype=torch.float32)
            target["labels"] = labels
            target["area"] = torch.as_tensor(areas, dtype=torch.float32)
            target["iscrowd"] = torch.zeros(len(boxes), dtype=torch.int64)
        else:
            # å°æ–¼æ²’æœ‰æ¨™è¨»çš„åœ–ç‰‡ (train æˆ– val)ï¼Œéƒ½æä¾›ç©ºçš„ tensors
            target["boxes"] = torch.empty((0, 4), dtype=torch.float32)
            target["labels"] = torch.empty((0,), dtype=torch.int64)
            target["area"] = torch.empty((0,), dtype=torch.float32)
            target["iscrowd"] = torch.empty((0,), dtype=torch.int64)

        # --- Transform æ‡‰ç”¨é‚è¼¯ (ä¸è®Š) ---
        # é€™è£¡çš„ is_train åˆ¤æ–·æ˜¯æ­£ç¢ºä¸”å¿…é ˆçš„ï¼Œå®ƒæ±ºå®šäº†æ•¸æ“šæ˜¯å¦è¢«å¢å¼·
        transform_pipeline = None
        if self.is_train:
            if 0 in self.transforms:  # æª¢æŸ¥æ˜¯å¦æ˜¯ Cluster-Aware æ¨¡å¼
                cluster_id = self.cluster_dict.get(frame_id, 0)
                transform_pipeline = self.transforms[cluster_id]
            else:  # Unified æ¨¡å¼
                transform_pipeline = self.transforms["unified"]
        else:  # Validation/Test æ¨¡å¼
            transform_pipeline = self.transforms["val"]

        image, target = transform_pipeline(image, target)

        return image, target


def create_cluster_dict(data_root: Path) -> dict:
    """
    Load cluster information from image_clusters.txt.

    Returns:
        Dictionary mapping frame_id -> cluster_id
    """
    cluster_path = data_root / "train" / "image_clusters.txt"
    if not cluster_path.exists():
        print(f"âš ï¸  Cluster file not found at {cluster_path}")
        return {}

    try:
        cluster_df = pd.read_csv(cluster_path, sep="\t")
        cluster_dict = dict(zip(cluster_df["frame_id"], cluster_df["cluster_id"]))

        # Print cluster statistics
        from collections import Counter

        cluster_counts = Counter(cluster_dict.values())
        print("ğŸ“Š Cluster distribution:")
        for cluster_id in sorted(cluster_counts.keys()):
            count = cluster_counts[cluster_id]
            percentage = count / len(cluster_dict) * 100
            print(f"   Cluster {cluster_id}: {count} images ({percentage:.1f}%)")

        return cluster_dict
    except Exception as e:
        print(f"âŒ Error loading cluster file: {e}")
        return {}
